{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer,RobustScaler\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import  GradientBoostingRegressor,GradientBoostingClassifier,AdaBoostRegressor,BaggingRegressor,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet,SGDClassifier,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error ,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=False\n",
    "train_dataset=pd.read_csv('INPUT/diamonds_train.csv',index_col=0)\n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40345, 10)"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=pd.read_csv('INPUT/diamonds_test.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13449, 9)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Encoding of the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried also the 'get dummies approach', but the label encoding performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['cut', 'color', 'clarity']\n",
    "train_dataset[cat_col]=train_dataset[cat_col].apply(LabelEncoder().fit_transform)\n",
    "train_dataset.dtypes\n",
    "train_dataset[cat_col]=train_dataset[cat_col]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[cat_col]=test_dataset[cat_col].apply(LabelEncoder().fit_transform)\n",
    "test_dataset[cat_col]=test_dataset[cat_col]+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. removing of 0-values and outliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 values of x and y columns\n",
    "train_dataset.loc[(train_dataset['x']==0) | (train_dataset['y']==0)]\n",
    "train_dataset=train_dataset.loc[(train_dataset['x']>0) | (train_dataset['y']>0)]\n",
    "train_dataset.loc[18027,'x']=train_dataset['x'].median()\n",
    "train_dataset.loc[18027,'z']=train_dataset['z'].median()\n",
    "train_dataset.loc[(train_dataset['z']==0)]\n",
    "\n",
    "#guessing of the missing z-values with an Elastic Net model\n",
    "cols=['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z',]\n",
    "m=ElasticNet()\n",
    "train_dataset_X=train_dataset.loc[0:10000,cols]\n",
    "train_dataset_y=train_dataset.loc[0:10000,'z']\n",
    "m.fit(train_dataset_X, train_dataset_y)\n",
    "test_dataset1=train_dataset.loc[(train_dataset['z']==0),cols]                                 \n",
    "y_pred=m.predict(test_dataset1)\n",
    "train_dataset.loc[train_dataset['z']==0,'z']=y_pred\n",
    "train_dataset.loc[(train_dataset['z']==0)]\n",
    "#removing of outliars of 'y' and 'z' columns\n",
    "train_dataset=train_dataset.loc[~(train_dataset['y']>30)|(train_dataset['z']>30)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Price and categorical features Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying log transformation to make the relation carat-price more linear\n",
    "flag=True\n",
    "train_dataset['logprice']=np.log(train_dataset['price'])\n",
    "train_dataset['price']=train_dataset['logprice']\n",
    "train_dataset.drop('logprice',axis=1,inplace=True)\n",
    "\n",
    "'''def trasf(x):\n",
    "    return x**(1/3)\n",
    "train_dataset['carat']=train_dataset['carat'].apply(trasf)\n",
    "test_dataset['carat']=test_dataset['carat'].apply(trasf)\n",
    "'''\n",
    "#applying a weight to the categorical features\n",
    "train_dataset['cut/wt']=train_dataset['cut']/train_dataset['carat']\n",
    "train_dataset['color/wt']=train_dataset['color']/train_dataset['carat']\n",
    "train_dataset['clarity/wt']=train_dataset['clarity']/train_dataset['carat']\n",
    "train_dataset = train_dataset.drop(['cut','color','clarity'], axis=1)\n",
    "\n",
    "test_dataset['cut/wt']=test_dataset['cut']/test_dataset['carat']\n",
    "test_dataset['color/wt']=test_dataset['color']/test_dataset['carat']\n",
    "test_dataset['clarity/wt']=test_dataset['clarity']/test_dataset['carat']\n",
    "test_dataset = test_dataset.drop(['cut','color','clarity'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. New flag column 'category' to highlight the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to divide my database in 2 or 3 different databasees, in order to create a more precise model for the different price ranges:\n",
    "Database1 (Normal datapoints): 0<carat<q_h2\n",
    "Database2 (Normal datapoints): q_h2<carat<q_h1\n",
    "Database3 (Normal datapoints): q_h1<carat<end\n",
    "Since the 2 model solution performed better I split the database in just 2 new databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15d0d2400>"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf+xjCPlnHUU8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "q_hi  = train_dataset[\"carat\"].quantile(1)\n",
    "q_h2  = train_dataset[\"carat\"].quantile(0.99)\n",
    "\n",
    "def fillcat(x):\n",
    "    if (x > q_h2)and(x<q_hi):\n",
    "        return 2\n",
    "    elif (x>q_hi):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#new column to assign each point to a database    \n",
    "train_dataset['category']=train_dataset['carat'].apply(fillcat)\n",
    "\n",
    "train_dataset['category'].value_counts().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x103c46a58>"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#same operation for the test dataset\n",
    "test_dataset['category']=test_dataset['carat'].apply(fillcat)\n",
    "test_dataset['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Prediction of the category column for the test_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final solution I did not include this passage. \n",
    "At the beginning I tried to make the division of the databases based on price, and I guessed the category of the test set points based on the other columns using a Random Forest classifier and other models. It did not perform better than my best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: GradientBoostingClassifier\n",
      "GradientBoostingClassifier 0.979300941993059\n",
      "[[0.99657925 0.00342075]\n",
      " [0.8        0.2       ]]\n",
      "Training model: GradientBoostingClassifierP\n",
      "GradientBoostingClassifierP 0.9768220128904314\n",
      "[[0.99125808 0.00874192]\n",
      " [0.67428571 0.32571429]]\n",
      "Training model: RandomForestClassifier\n",
      "RandomForestClassifier 0.979300941993059\n",
      "[[0.99341188 0.00658812]\n",
      " [0.65714286 0.34285714]]\n",
      "Training model: Logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silviaserafini/Library/Python/3.6/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic 0.9797967278135845\n",
      "[[0.9953123 0.0046877]\n",
      " [0.72      0.28     ]]\n",
      "Training model: SuperVectorC\n",
      "SuperVectorC 0.9783093703520079\n",
      "[[1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'m =RandomForestClassifier(bootstrap=True,max_depth=70,\\n                            max_features=\\'auto\\',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\\n\\nm.fit(X_train1, y_train1)\\nprint(\"Training complete\")\\ny_pred=m.predict(X_test1)\\naccuracy_score(y_test1, y_pred)'"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Accuracy test\n",
    "if flag:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z']#, 'cut/wt', 'color/wt',\n",
    "      #'clarity/wt']\n",
    "else:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z']#, 'cut', 'color',\n",
    "      #     'clarity']\n",
    "\n",
    "train_dataset_X=train_dataset[cols]\n",
    "train_dataset_y=train_dataset['category']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_dataset_X, train_dataset_y, test_size = 0.2, random_state = 0)\n",
    "models = {\n",
    "    \"GradientBoostingClassifier\" : GradientBoostingClassifier(),\n",
    "    \"GradientBoostingClassifierP\" : GradientBoostingClassifier(n_estimators=500, learning_rate=0.3),\n",
    "    \"RandomForestClassifier\" : RandomForestClassifier(n_estimators=100),\n",
    "    \"Logistic\" : LogisticRegression(),\n",
    "    \"SuperVectorC\" : SVC()\n",
    "}\n",
    "\n",
    "for modelName, model in models.items():\n",
    "    print(f\"Training model: {modelName}\")\n",
    "    model.fit(X_train1, y_train1)\n",
    "    y_pred=model.predict(X_test1)\n",
    "    print(modelName,accuracy_score(y_test1, y_pred))\n",
    "    print(confusion_matrix(y_test1, y_pred, normalize='true'))\n",
    "#m =RandomForestClassifier(bootstrap=True,max_depth=70,\n",
    "                        #    max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "\n",
    "#m.fit(X_train1, y_train1)\n",
    "#print(\"Training complete\")\n",
    "#y_pred=m.predict(X_test1)\n",
    "#accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99569239, 0.00430761],\n",
       "       [0.41142857, 0.58857143]])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test1, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "'''if flag:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut/wt', 'color/wt',\n",
    "       'clarity/wt'\n",
    "       ]\n",
    "else:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "           'clarity'\n",
    "           ]\n",
    "\n",
    "train_dataset_X=train_dataset[cols]\n",
    "train_dataset_y=train_dataset['category']\n",
    " \n",
    "m =RandomForestClassifier(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "    \n",
    "m.fit(train_dataset_X, train_dataset_y)\n",
    "print(\"Training complete\")\n",
    "y_pred=m.predict(test_dataset[cols])\n",
    "test_dataset['category']=y_pred'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. training of the 2 models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trie also the 3-models approach, but did not perform better than the 2 models approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "1899.7648468875086\n"
     ]
    }
   ],
   "source": [
    "#first model for outliars 0.99-1\n",
    "if flag:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut/wt', 'color/wt',\n",
    "           'clarity/wt']\n",
    "else:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "           'clarity']\n",
    "       \n",
    "train_dataset_X1=train_dataset[train_dataset.category ==2][cols]\n",
    "train_dataset_y1=train_dataset[train_dataset.category ==2]['price']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_dataset_X1, train_dataset_y1, test_size = 0.1, random_state = 0)\n",
    "m2 =RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "\n",
    "m2.fit(X_train1, y_train1)\n",
    "\n",
    "print(\"Training complete\")\n",
    "if flag:\n",
    "    y_test2=np.exp(y_test1)\n",
    "    y_pred1=m2.predict(X_test1)\n",
    "    y_pred2=np.exp(y_pred1)\n",
    "    print(mean_squared_error(y_test2, y_pred2,squared=False))\n",
    "else:\n",
    "    y_test2=np.exp(y_test1)\n",
    "    y_pred1=m2.predict(X_test1)\n",
    "    y_pred2=np.exp(y_pred1)\n",
    "    print(mean_squared_error(y_test2, y_pred2,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not included on the final solution\n",
    "'''#second model for outliars 0.98-1\n",
    "if flag:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut/wt', 'color/wt',\n",
    "           'clarity/wt']\n",
    "else:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "           'clarity']\n",
    "       \n",
    "train_dataset_X1=train_dataset[train_dataset.category ==1][cols]\n",
    "train_dataset_y1=train_dataset[train_dataset.category ==1]['price']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train_dataset_X1, train_dataset_y1, test_size = 0.1, random_state = 0)\n",
    "m1 =RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "    \n",
    "\n",
    "m1.fit(X_train1, y_train1)\n",
    "print(\"Training complete\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022.1808154195353\n"
     ]
    }
   ],
   "source": [
    "if flag:\n",
    "    y_test2=np.exp(y_test1)\n",
    "    y_pred1=m1.predict(X_test1)\n",
    "    y_pred2=np.exp(y_pred1)\n",
    "    print(mean_squared_error(y_test2, y_pred2,squared=False))\n",
    "else:\n",
    "    y_test2=np.exp(y_test1)\n",
    "    y_pred1=m1.predict(X_test1)\n",
    "    y_pred2=np.exp(y_pred1)\n",
    "    print(mean_squared_error(y_test2, y_pred2,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563.1688840090344\n"
     ]
    }
   ],
   "source": [
    "#this was a test to see how the model trained with the 'normal points' performed in the outlairs prediction.\n",
    "'''prova da eliminare\n",
    "m0 =RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "train_dataset_X0=train_dataset[cols]\n",
    "train_dataset_y0=train_dataset['price']\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(train_dataset_X0, train_dataset_y0, test_size = 0.2, random_state = 0)\n",
    "m0.fit(X_train0, y_train0)  \n",
    "y_test2=np.exp(y_test0)\n",
    "y_predout=m0.predict(X_test0)\n",
    "y_pred2=np.exp(y_predout)\n",
    "print(mean_squared_error(y_test2, y_pred2,squared=False))\n",
    " \n",
    "y_test2=np.exp(y_test1)\n",
    "y_predout=m0.predict(X_test1)\n",
    "y_pred2=np.exp(y_predout)\n",
    "print(mean_squared_error(y_test2, y_pred2,squared=False))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "#third model, for normal values (0->0.99)\n",
    "if flag:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut/wt', 'color/wt',\n",
    "           'clarity/wt'\n",
    "           ]\n",
    "else:\n",
    "    cols=['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "           'clarity'\n",
    "           ]\n",
    "train_dataset_X0=train_dataset[train_dataset.category ==0][cols]\n",
    "train_dataset_y0=train_dataset[train_dataset.category ==0]['price']\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(train_dataset_X0, train_dataset_y0, test_size = 0.2, random_state = 0)\n",
    "m0 =RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "    \n",
    "m0.fit(X_train0, y_train0)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520.1713827720228\n"
     ]
    }
   ],
   "source": [
    "if flag:\n",
    "    y_test3=np.exp(y_test0)\n",
    "    y_pred0=m0.predict(X_test0)\n",
    "    y_pred3=np.exp(y_pred0)\n",
    "    print(mean_squared_error(y_test3, y_pred3,squared=False))\n",
    "else:\n",
    "    y_test3=np.exp(y_test0)\n",
    "    y_pred0=m0.predict(X_test0)\n",
    "    y_pred3=np.exp(y_pred0)\n",
    "    print(mean_squared_error(y_test3, y_pred3,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533.79"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#guess of the weighted RMSE of the ensambled model. Maybe it is not the best way to predict it.\n",
    "520*0.99+1899*0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained the models with the test_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=70, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=2,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=700, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2==RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "  \n",
    "'''m1==RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    " '''   \n",
    "m0 =RandomForestRegressor(bootstrap=True,max_depth=70,\n",
    "                            max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=700)\n",
    "\n",
    "#filters for the test database with the labels of the column that I created\n",
    "'''outliers=train_dataset.category ==1'''\n",
    "outliers2=train_dataset.category ==2\n",
    "normal=train_dataset.category ==0\n",
    "\n",
    "#creation of the databases\n",
    "train_dataset0= train_dataset[normal]\n",
    "'''train_dataset1= train_dataset[outliers]'''\n",
    "train_dataset2= train_dataset[outliers2]\n",
    "\n",
    "#fitting of the 2 models: m0:normal points, m2: outliars (top1% of carat)\n",
    "m0.fit(train_dataset0[cols], train_dataset0['price'])\n",
    "'''m1.fit(train_dataset1[cols], train_dataset1['price'])'''\n",
    "m2.fit(train_dataset2[cols], train_dataset2['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction of the models\n",
    "'''y_predoutliers=m1.predict(test_dataset[cols])'''\n",
    "y_prednormal=m0.predict(test_dataset[cols])\n",
    "y_intermediate=m2.predict(test_dataset[cols])\n",
    "\n",
    "#filters\n",
    "'''usefirstmodel=test_dataset['category']==1'''\n",
    "usesecondmodel=test_dataset['category']==2\n",
    "\n",
    "#merging of the predictions of the 2 models.\n",
    "y_pred=y_prednormal\n",
    "'''y_pred[usefirstmodel]=y_predoutliers[usefirstmodel]'''\n",
    "y_pred[usesecondmodel]=y_intermediate[usesecondmodel]\n",
    "                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Saving of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2296bf6d8>"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAcDMzPDwcDMzHAwMDMz4P8DVzGMAzrYIGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I plotted the current solution vs my best solution to check the differencies\n",
    "fil=pd.read_csv('submissionDoubleModelCarat98.csv')\n",
    "y_pred2=np.exp(y_pred)\n",
    "fil.shape\n",
    "plt.scatter(tentative,fil['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation of the answer\n",
    "df=pd.DataFrame(y_pred2)\n",
    "df=df.reset_index()\n",
    "df.columns=('Id','price')\n",
    "df[['Id', 'price']].to_csv('submissionDouble533Model99.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Final  tentative to combine my 2 best scored solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    13426\n",
       "True        23\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission1=pd.read_csv('submissionDoubleModelCarat98.csv')\n",
    "doublemodel=pd.read_csv('submissionAutoML.csv')\n",
    "\n",
    "tentative=(submission1['price']+doublemodel['price'])/2\n",
    "\n",
    "#If the difference of the 2 solution is higher than 1200, I replace the value with the most secure solution\n",
    "diff=(submission1['price']-doublemodel['price'])\n",
    "\n",
    "filter1=(diff>1200) | (diff <-1200)\n",
    "filter1.value_counts()\n",
    "tentative[filter1]=submission1['price'][filter1]\n",
    "filter1.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission of the Hybrid solution\n",
    "doublemodel['price']=tentative\n",
    "doublemodel[['Id', 'price']].to_csv('submissionHybridHope1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
